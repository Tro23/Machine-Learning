{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "earlier-luxury",
   "metadata": {},
   "source": [
    "### ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "medical-japan",
   "metadata": {},
   "source": [
    "ML Pipelines are cyclical and iterative as every step is repeated to finally achieve a successful algorithm."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "purple-assault",
   "metadata": {},
   "source": [
    "#### Key Stages in building ML Pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "physical-modern",
   "metadata": {},
   "source": [
    "<UL>\n",
    "    <li><b>Problem Definition:</b>Define the business problem you require an answer for.</li>\n",
    "    <br>\n",
    "    <li><b>Data Ingestion:</b>Identify and gather the data you want to work with.</li>\n",
    "    <br>\n",
    "    <li><b>Data Preparation:</b>Since the data is raw and unstructured, it is rarely in the correct form to be processed. It usually involves <i>filling missing values</i> or <i>removing duplicate records</i> or <i>normalising</i> and correcting other flaws in data, like different representations of the same values in a column for instance. This is where the <i>feature extraction, construction and selection takes place too.</i></li>\n",
    "    <br>\n",
    "    <li><b>Data Segregation:</b> Split subsets of data to train the model, test it and further validate how it performs against new data.</li>\n",
    "    <br>\n",
    "    <li><b>Model Training:</b> Use the training subset of data to let the <i>ML algorithm</i> recognise the patterns in it.</li>\n",
    "    <br>\n",
    "    <li><b>Candidate Model Evaluation:</b> Assess the performance of the model using test and validation subsets of data to understand how accurate the prediction is. This is an iterative process and <i>various algorithms might be tested until you have a Model that sufficiently answers your question.</i></li>\n",
    "    <br>\n",
    "    <li><b>Model Deployment:</b> Once the chosen model is produced, it is typically <i>exposed via some kind of API and embedded in decision-making frameworks as a part of an analytics solution.</i></li>\n",
    "    <br>\n",
    "    <li><b>Performance Monitoring:</b> The model is continuously monitored to observe how it behaved in the real world and calibrated accordingly. <i>New data is collected to incrementally improve it.</i></li>\n",
    "</UL>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "finnish-smile",
   "metadata": {},
   "source": [
    "### Architecting a ML Pipeline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "younger-casino",
   "metadata": {},
   "source": [
    "Traditionally, pipelines involve overnight batch processing, i.e.<b><i> collecting data, sending it through an enterprise message bus and processing it to provide pre-calculated results</i></b> and guidance for next day’s operations."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "criminal-drive",
   "metadata": {},
   "source": [
    "#### Batch Processing mode? : \n",
    "<br>\n",
    "Processes large volume of data all at once. May Require dedicated staff to handle issues."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "collectible-migration",
   "metadata": {},
   "source": [
    "#### Note:\n",
    "<br>\n",
    "<b>NoSQL document databases</b> are ideal for storing large volumes of rapidly changing structured and/or unstructured data, since they are schema-less. They also offer a distributed, scalable, replicated data storage."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "soviet-dispatch",
   "metadata": {},
   "source": [
    "### Data Ingestion\n",
    "<br>\n",
    "\n",
    "    Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "multiple-arctic",
   "metadata": {},
   "source": [
    "#### Offline Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "representative-development",
   "metadata": {},
   "source": [
    "In the offline layer, data flows into the <b> RAW DATA STORE</b> via an <b><i>Ingestion Service</i></b> - a composite orchestration service, which encapsulates the data sourcing and persistence. \n",
    "\n",
    "<br>\n",
    "Internally, a repository pattern is employed to interact with a data service, which in return interacts with the data store. When the data is saved in the database, a unique batch-id is assigned to the dataset, to allow for efficient querying and end-to-end data lineage and traceability."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cordless-cooper",
   "metadata": {},
   "source": [
    "To be performant, the <i>ingestion distribution</i> is <b>TwoFold</b>:\n",
    "<br>\n",
    "<ul>\n",
    "    <li> There is a <i>dedicated pipeline</i> for <b>each dataset</b> so all of them are processed independently and <i>concurrently</i>, and</li>\n",
    "    <li> Within each pipeline, the data is <b>partitioned</b> to take advantage of the multiple server cores, processors or even servers.(example: <b>MongoDB</b>)</li>\n",
    "</ul>\n",
    "<br>\n",
    "Spreading the data preparation across multiple pipelines, horizontally and vertically, reduces the overall time to complete the job."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "noted-bunny",
   "metadata": {},
   "source": [
    "#### Online Layer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "designing-grove",
   "metadata": {},
   "source": [
    "In the online layer, the <b>Online Ingestion Service</b> is the <i>entry point</i> to the streaming architecture as it <i>decouples and manages the flow of information</i> from data sources to the processing and storage components, by providing <b>reliable, high throughput, low latency capabilities</b>.\n",
    "\n",
    "<br>\n",
    "It functions as an <i>enterprise-scale</i>'<b>Data Bus</b>'.\n",
    "\n",
    "<br>\n",
    "\n",
    "Data is saved in along term Raw Data Store, but is also passed through a '<b>pass-through layer</b>' to the next online streaming service, for further real-time processing."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "environmental-lloyd",
   "metadata": {},
   "source": [
    "Example technologies used here can be <b>Apache Kafka</b> (pub/sub messaging system) and<b> Apache Flume</b> (data collection to long term db)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protected-aviation",
   "metadata": {},
   "source": [
    "### Data Preparation\n",
    "<br>\n",
    "\n",
    "    Data exploration, data transformation and feature engineering."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "alternate-startup",
   "metadata": {},
   "source": [
    "Once the data is ingested, a distributed pipeline is generated which assesses the <i>condition of the data</i>, i.e. <b>looks for format differences, outliers, trends, incorrect, missing, or skewed data</b> and <b>rectify any anomalies</b> along the way."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "french-judges",
   "metadata": {},
   "source": [
    "This step also includes feature engineering process.\n",
    "<br>\n",
    "\n",
    "Three main phases in <i>feature pipeline</i>:\n",
    "<ul>\n",
    "    <li><b>Extraction:</b> <i>Input</i> :'<b>Raw Data</b>' <b>|</b> <i>Output</i> :'<b>Features</b></li>\n",
    "    <br>\n",
    "    <li><b>Transformation:</b> <i>Input</i> :'<b>Features</b>' <b>|</b> <i>Output</i> :'<b>Features(<i>transformations</i>)</b>'<li>\n",
    "    <br>\n",
    "    <li><b>Selection:</b> <i>Input</i> :'<b>List[Features]</b>' <b>|</b> <i>Output</i> :'<b>List[Features]</b>'</li>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-transsexual",
   "metadata": {},
   "source": [
    "#### THIS step is the most complex part of the ML Project."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "third-basin",
   "metadata": {},
   "source": [
    "Introducing the right design patterns is crucial, so in terms of code organisation:\n",
    "\n",
    "<br>\n",
    "    having a factory method to generate the features based on <i>some common abstract feature behaviour</i> as well as a <i>strategy pattern</i> to allow the selection of the <b>right features at run time</b> is a sensible approach."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "traditional-delicious",
   "metadata": {},
   "source": [
    "Both <i>feature extractors</i> and <i>transformers</i> should be structured with <b>composition</b> and <b>re-usability</b> in mind."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "overall-basis",
   "metadata": {},
   "source": [
    "Broadly speaking, a <i>data preparation pipeline</i> should be assembled into a <b>series of immutable transformations</b>, that can easily be combined. \n",
    "\n",
    "<br>\n",
    "This is where the <b>significance</b> of<i> testing and high code coverage</i> becomes an important factor for the project’s success."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "sixth-community",
   "metadata": {},
   "source": [
    "### Offline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "auburn-collect",
   "metadata": {},
   "source": [
    "In the offline layer, the <b>Data Preparation Service</b>, is <i>triggered</i> by the <i>completion of the ingestion service</i>. It sources the <b>Raw Data</b>, undertakes <b>all the feature engineering logic</b>, and <i>saves the generated features</i> in the <b>Feature Data Store.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accepting-groove",
   "metadata": {},
   "source": [
    "Same <b>TwoFold</b> Partitioning applies here in Data Preparation as it did in Data Ingestion. \n",
    "            (<b>Dedicated and Parallel Pipelines</b>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "about-jersey",
   "metadata": {},
   "source": [
    "Optionally, the features from <i>multiple data sources can be <b>combined</b></i>, so a <b>‘join/sync’ task</b> is designed to <i>aggregate all the intermediate completion events</i> and <i>create these new, combined features</i>. \n",
    "\n",
    "<br>\n",
    "In the end, the <i>notification service broadcasts to the <b>broker</b>. This process is complete and the <i>features are available.</i>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "korean-rebate",
   "metadata": {},
   "source": [
    "When each data preparation pipeline ﬁnishes, <b>the features are also replicated to the Online Feature Data Store</b>, so that the features can be queried with low latency for real-time prediction."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "acting-panama",
   "metadata": {},
   "source": [
    "### Online"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "legislative-gardening",
   "metadata": {},
   "source": [
    "The raw data is streamed from the ingestion pipeline into the <b>Online Data Preparation Service</b>. \n",
    "\n",
    "<br>\n",
    "The generated features are stored in an <b>in-memory Online Feature Data Store</b> where they can be <i>read at low latency</i> at prediction time, but are also persisted in the long term Feature Data Store for future training."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "variable-negative",
   "metadata": {},
   "source": [
    "Additionally the in-memory database can be <b>pre-warmed</b> by loading features from the <b>long term Feature Data Store</b>.\n",
    "\n",
    "<br>\n",
    "A frequently used streaming engine is <b>Apache Spark.</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "parental-ideal",
   "metadata": {},
   "source": [
    "### Data Segregation\n",
    "    Splits subsetss of data to train the model & further validate how it performs against new data."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "communist-surgery",
   "metadata": {},
   "source": [
    "The fundamental goal of the ML system is to use an accurate model based on the <b>quality</b> of its pattern prediction for data that it has not been trained on. As such, existing labelled data is used as a <b>proxy</b> <i>for</i> <b>future/unseen</b> data, by splitting it into training and evaluation subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "governmental-amendment",
   "metadata": {},
   "source": [
    "The data <b>segregation</b> is not a separate ML pipeline as such, but <b>an API or service</b> must be available to facilitate this task. \n",
    "\n",
    "<br>\n",
    "The next two pipelines (<b>model training</b> and <b>evaluation</b>) must be able to call this API to get back the requested datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "russian-arrest",
   "metadata": {},
   "source": [
    "In terms of code organisation, a <b>strategy pattern</b> is necessary so the caller service can select the <b>right algorithm</b> at run time, and obviously the ability to inject the ratio or random seed is needed.\n",
    "\n",
    "<br>\n",
    "Additionally, the <b>API must be</b> able to return the data with or without labels/traits — for training and evaluation respectively.\n",
    "\n",
    "<br>\n",
    "\n",
    "To protect the caller from specifying parameters that cause an <b>uneven data distribution</b>, a warning should be raised and returned along with the dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "helpful-bedroom",
   "metadata": {},
   "source": [
    "### Model Training\n",
    "    Use the training subset of data to let the ML algorithm recognise the patterns in it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "thick-banana",
   "metadata": {},
   "source": [
    "### Side NOTE:\n",
    "            each model implementation would be a subclass of an abstract class that requires model maker to implement estimate() and predict() methods. But since you mentioned making wrappers for jupyter notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "northern-respect",
   "metadata": {},
   "source": [
    "### Side Note:\n",
    "\n",
    "<br>\n",
    "<b>Affinity Propagation</b> is an unsupervised machine learning algorithm that is particularly well suited for problems where we don't know the optimal number of <b>Cluster</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-rotation",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
